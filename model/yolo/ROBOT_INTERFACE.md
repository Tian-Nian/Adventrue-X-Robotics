# æœºå™¨äººæ§åˆ¶æ¥å£ä½¿ç”¨è¯´æ˜

## æ¦‚è¿°

è¿™ä¸ªé¡¹ç›®æä¾›äº†ä¸€ä¸ªåŸºäºYOLOå§¿æ€æ£€æµ‹çš„æœºå™¨äººæ§åˆ¶æ¥å£ï¼Œå¯ä»¥è¯†åˆ«è¹²ç€çš„äººå¹¶ç”Ÿæˆç›¸åº”çš„æœºå™¨äººæ§åˆ¶æŒ‡ä»¤ã€‚

## æœºå™¨äººæ§åˆ¶æŒ‡ä»¤

ç³»ç»Ÿæ”¯æŒå››ç§æ§åˆ¶æŒ‡ä»¤ï¼š

1. **`left`** - å‘å·¦è½¬ï¼šç›®æ ‡åœ¨æœºå™¨äººå·¦ä¾§ï¼Œéœ€è¦å‘å·¦è°ƒæ•´æ–¹å‘
2. **`right`** - å‘å³è½¬ï¼šç›®æ ‡åœ¨æœºå™¨äººå³ä¾§ï¼Œéœ€è¦å‘å³è°ƒæ•´æ–¹å‘  
3. **`forward`** - å‘å‰ç§»åŠ¨ï¼šç›®æ ‡åœ¨å‰æ–¹åŒºåŸŸï¼Œå‘å‰é è¿‘ç›®æ ‡
4. **`rotate`** - åŸåœ°æ—‹è½¬ï¼šæœªæ£€æµ‹åˆ°è¹²ç€çš„ç›®æ ‡ï¼ŒåŸåœ°æ—‹è½¬å¯»æ‰¾

## æ§åˆ¶é€»è¾‘

- **æœ‰è¹²ç€çš„ç›®æ ‡æ—¶**ï¼šæ ¹æ®ç›®æ ‡åœ¨ç”»é¢ä¸­çš„ä½ç½®å†³å®šå‘å·¦ã€å‘å³æˆ–å‘å‰
- **æ— è¹²ç€çš„ç›®æ ‡æ—¶**ï¼šåŸåœ°æ—‹è½¬å¯»æ‰¾ç›®æ ‡
- **å¤šä¸ªç›®æ ‡æ—¶**ï¼šä¼˜å…ˆé€‰æ‹©å§¿æ€ç½®ä¿¡åº¦æœ€é«˜çš„ç›®æ ‡

## å¿«é€Ÿå¼€å§‹

### 1. ç®€å•æ¥å£ä½¿ç”¨

```python
from process import robot_interface, create_robot_controller
import cv2

# åˆ›å»ºæœºå™¨äººæ§åˆ¶å™¨
model, opt = create_robot_controller('path/to/your/model.bin')

# åˆå§‹åŒ–ç›¸æœº
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # è·å–æœºå™¨äººæ§åˆ¶æŒ‡ä»¤
    robot_cmd = robot_interface(frame, model, opt)
    
    # æå–æŒ‡ä»¤ä¿¡æ¯
    command = robot_cmd['command']        # 'left', 'right', 'forward', 'rotate'
    confidence = robot_cmd['confidence']  # 0.0 - 1.0
    target_detected = robot_cmd['target_detected']  # True/False
    reason = robot_cmd['reason']          # æŒ‡ä»¤åŸå› è¯´æ˜
    
    # æ ¹æ®æŒ‡ä»¤æ§åˆ¶æœºå™¨äººï¼ˆéœ€è¦æ ¹æ®å®é™…æœºå™¨äººæ¥å£ä¿®æ”¹ï¼‰
    if confidence > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
        if command == 'left':
            print("ğŸ¤– å‘å·¦è½¬")
            # your_robot.turn_left()
        elif command == 'right':
            print("ğŸ¤– å‘å³è½¬")  
            # your_robot.turn_right()
        elif command == 'forward':
            print("ğŸ¤– å‘å‰ç§»åŠ¨")
            # your_robot.move_forward()
        elif command == 'rotate':
            print("ğŸ¤– åŸåœ°æ—‹è½¬")
            # your_robot.rotate()
    
    print(f"æŒ‡ä»¤: {command}, ç½®ä¿¡åº¦: {confidence:.2f}")

cap.release()
```

### 2. è¯¦ç»†æ¥å£ä½¿ç”¨

```python
from process import robot_interface, create_robot_controller
import cv2

# åˆ›å»ºæœºå™¨äººæ§åˆ¶å™¨ï¼ˆå¯è‡ªå®šä¹‰å‚æ•°ï¼‰
model, opt = create_robot_controller(
    model_path='path/to/your/model.bin',
    score_thres=0.3,        # æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
    knee_angle_thres=165,   # è†ç›–å¼¯æ›²è§’åº¦é˜ˆå€¼
    hip_angle_thres=160     # é«‹éƒ¨å¼¯æ›²è§’åº¦é˜ˆå€¼
)

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # è·å–å®Œæ•´çš„æœºå™¨äººæ§åˆ¶ä¿¡æ¯
    robot_cmd = robot_interface(frame, model, opt)
    
    command = robot_cmd['command']
    confidence = robot_cmd['confidence'] 
    target_detected = robot_cmd['target_detected']
    target_info = robot_cmd['target_info']  # ç›®æ ‡è¯¦ç»†ä¿¡æ¯
    reason = robot_cmd['reason']
    
    print(f"æŒ‡ä»¤: {command}, ç½®ä¿¡åº¦: {confidence:.2f}, åŸå› : {reason}")
    
    if target_detected and target_info:
        pos = target_info['position']
        bbox = target_info['bbox']
        pose_conf = target_info['pose_confidence']
        print(f"ç›®æ ‡ä½ç½®: {pos}, å§¿æ€ç½®ä¿¡åº¦: {pose_conf:.2f}")
    
    # æ§åˆ¶æœºå™¨äºº
    control_robot(command, confidence)

cap.release()

def control_robot(command, confidence):
    """æ ¹æ®æŒ‡ä»¤æ§åˆ¶æœºå™¨äººçš„ç¤ºä¾‹å‡½æ•°"""
    if confidence < 0.5:
        return  # ç½®ä¿¡åº¦å¤ªä½ï¼Œä¸æ‰§è¡Œ
        
    if command == 'left':
        # å‘å·¦è½¬çš„å®ç°
        pass
    elif command == 'right':
        # å‘å³è½¬çš„å®ç° 
        pass
    elif command == 'forward':
        # å‘å‰ç§»åŠ¨çš„å®ç°
        pass
    elif command == 'rotate':
        # åŸåœ°æ—‹è½¬çš„å®ç°
        pass
```

## è¿”å›å€¼è¯´æ˜

`robot_interface()` å‡½æ•°è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```python
{
    'command': str,           # æ§åˆ¶æŒ‡ä»¤ï¼š'left', 'right', 'forward', 'rotate'
    'confidence': float,      # æŒ‡ä»¤ç½®ä¿¡åº¦ (0.0-1.0)
    'target_detected': bool,  # æ˜¯å¦æ£€æµ‹åˆ°è¹²ç€çš„ç›®æ ‡
    'target_info': dict,      # ç›®æ ‡è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ç›®æ ‡ï¼‰
    'reason': str            # æŒ‡ä»¤ç”ŸæˆåŸå› è¯´æ˜
}
```

### target_info è¯¦ç»†å­—æ®µ

å½“æ£€æµ‹åˆ°ç›®æ ‡æ—¶ï¼Œ`target_info` åŒ…å«ï¼š

```python
{
    'position': (x, y),              # ç›®æ ‡ä¸­å¿ƒåæ ‡
    'bbox': (x1, y1, x2, y2),       # ç›®æ ‡è¾¹ç•Œæ¡†
    'detection_confidence': float,   # ç›®æ ‡æ£€æµ‹ç½®ä¿¡åº¦
    'pose_confidence': float,        # å§¿æ€åˆ†æç½®ä¿¡åº¦  
    'pose_status': str              # å§¿æ€çŠ¶æ€ï¼š'standing' æˆ– 'crouching'
}
```

## é…ç½®å‚æ•°

å¯ä»¥é€šè¿‡ `create_robot_controller()` çš„å‚æ•°è°ƒæ•´æ£€æµ‹è¡Œä¸ºï¼š

```python
model, opt = create_robot_controller(
    model_path='model.bin',
    score_thres=0.25,        # ç›®æ ‡æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
    knee_angle_thres=165,    # è†ç›–è§’åº¦é˜ˆå€¼ï¼ˆå°äºæ­¤å€¼è®¤ä¸ºè¹²ä¸‹ï¼‰
    hip_angle_thres=160,     # é«‹éƒ¨è§’åº¦é˜ˆå€¼ï¼ˆå°äºæ­¤å€¼è®¤ä¸ºè¹²ä¸‹ï¼‰
    min_kpt_conf=0.15,       # å…³é”®ç‚¹æœ€å°ç½®ä¿¡åº¦
    min_valid_kpts=2         # æœ€å°‘æœ‰æ•ˆå…³é”®ç‚¹æ•°
)
```

## æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹æ–‡ä»¶**ï¼šéœ€è¦æä¾›åˆé€‚çš„YOLOå§¿æ€æ£€æµ‹æ¨¡å‹æ–‡ä»¶
2. **ç½®ä¿¡åº¦æ§åˆ¶**ï¼šå»ºè®®è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆå¦‚0.5ï¼‰é¿å…è¯¯æ“ä½œ
3. **å®æ—¶æ€§**ï¼šæ ¹æ®ç¡¬ä»¶æ€§èƒ½è°ƒæ•´æ£€æµ‹é¢‘ç‡
4. **å®‰å…¨æ€§**ï¼šåœ¨å®é™…æœºå™¨äººä¸Šä½¿ç”¨æ—¶è¦è€ƒè™‘å®‰å…¨æªæ–½

## æµ‹è¯•ä¸è°ƒè¯•

è¿è¡ŒåŸæœ‰çš„å¯è§†åŒ–ç¨‹åºè¿›è¡Œæµ‹è¯•ï¼š

```bash
python model.py --model-path your_model.bin --camera-id 0
```

æŒ‰é”®åŠŸèƒ½ï¼š
- `q`: é€€å‡º
- `s`: ä¿å­˜å½“å‰å¸§  
- `i`: æ˜¾ç¤ºç›¸æœºä¿¡æ¯
- `c`: æ˜¾ç¤ºå½“å‰æŒ‡ä»¤çŠ¶æ€
- `t`: æ˜¾ç¤ºæ§åˆ¶è¯´æ˜ 